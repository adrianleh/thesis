\chapter{Basics and related work}\label{sec:basics}

% Compiler
\section{Compiler}\label{sec:basics:compiler}

The basic function of a compiler is to automatically convert high-level code created by a developer into (optimized) machine code.
As a compiler is an inherently large software project, an architecture needs to be chosen that allows for extensions and modifications easily.
Modern compilers mostly follow a layered architecture style: They are each comprised of a front-, middle-, and back-end.
In this architecture, the front-end converts the high-level code into an abstract intermediary representation that is then used by the middle-end for optimizations and transformations.
Lastly, the backend is responsible for converting the optimized intermediary code into instructions for the target system architecture (e.g. \texttt{RISC-V}, \texttt{x86}, \texttt{ARM}, etc.).

% Basic blocks
\section{Basic blocks and control-flow}\label{sec:basics:bb-cf}

To better handle code and give it a logical structure, most compilers divide code up into so-called \textit{basic blocks}.
Basic blocks are sets of consecutive operations that do not contain jumps or targets of thereof, but rather only jumps connecting them.
Therefore, a basic block is either be executed completely or not executed at all.

A usual way to represent this in a human-readable form is to output it as a control-flow-graph (CFG).
CFGs depict basic blocks as nodes and jumps between basic blocks as edges.
Furthermore, it is a convention in these graphs to have exactly one start-node, and one end-node.

It is to be noted that CFGs, in general, are cyclical graphs.
They only are non-cyclical graphs, iff the original code does not contain any jumps going backward in the control-flow.

Another important concept of CFGs is dominance.
In order to explain this concept, a starting node $S$ is defined, and it is assumed there are two (not necessarily different) nodes, present in the CFG, $N_1$, and $N_2$.
With this information, dominance is defined as follows:
$$N_1~\text{dominates}~N_2 \Longleftrightarrow \forall p \in \text{Paths}(S, N_2):~N_1 \in p$$
In lucid terms this means that $N_1$ dominates $N_2$, iff in order to get to $N_2$ from $S$ you have to visit $N_1$ on the way.
It is important to note that a block always dominates itself.

% Lifetime

\section{Loops}\label{sec:basics:loops}

We define a loop to be as a set of nodes that are all in a cyclical control-flow structure.
Formally this can be expressed as:

$$L~\text{is a loop} \Longleftrightarrow L \neq \emptyset \wedge \forall n_1, n_2 \in L:~\exists Path(n_1, n_2)$$

If a loop is completely contained inside another loop, it is said to be nested.

$$\tilde{L}~\text{is nested in}~L \Longleftrightarrow \forall n \in \tilde{L}: n \in L$$

If a loop has no nested loops inside of it we will henceforth call it the \textit{innermost} loop.

$$L~\text{is innermost loop} \Longleftrightarrow L~\text{is a loop}~\wedge \nexists L' \subsetneq L: L'~\text{is a loop}$$

Loops can furthermore have a header, which is the sole entry point into a loop~\cite{aebi18bachelorarbeit} and defined as follows

$$H~\text{is header of}~L \Longleftrightarrow H \in L \wedge \forall n \in L: H~\text{dominates}~n$$

N.B.: Not all loops have to have a header.

If a loop has a header, its body is the set of all nodes in the loop, except for the header.
$$B~\text{is body of}~L \Longleftrightarrow B = L \backslash \{H\}, H~\text{is header of}~L$$

% SSA
\section{Single-Static-Assignment (SSA)}\label{sec:basics:ssa}

The \textit{single-static-assignment} (\textit{SSA}) form is a property of intermediary representations, that requires each variable to only be assigned exactly once.
Moreover, every value has to be assigned before it is being used~\cite{cytron91}.
This especially implies that the block in which a given value $v$ is declared has to dominate all blocks in which $v$ is used, and that this declaration point will be unambiguous across all possible usages.

The SSA form is used to simplify optimzations in the regard that one can be sure, that a given value in use is currently defined by a set point in the code.

An example of a program in SSA form can be seen in~\cref{fig:basics:SSA-simple}.
Whilst in the base code $x$ is assigned twice, in the code transformed into SSA form, simply a new value was defined to make sure, that each variable is only define once.

\input{fig/simple-ssa-example.tex}

In a loop or a conditional statement, a scenario might arise where multiple values could be assigned to a given value.
In cases like these a \textit{$\Phi$-function} can be used.
A $\Phi$-function is a theoretical construct that returns the correct value depending on the control-flow predecessor.

An example the use of a $\Phi$-function this can be seen in~\cref{fig:basics:SSA-phi}, where a depending on the control-flow either $m_1$ or $m_2$ are selected.

\input{fig/max-ssa.tex}

% LCSAA

\section{Loop-Closed-Single-Static-Assignment (LCSSA)}\label{sec:basics:LCSSA}

An extension to the SSA form is the \textit{loop-closed-single-static-assignment} (\textit{LCSSA}) form.
It in addition to the properties guaranteed by the regular SSA form a CFG in LCSSA has the property that each variable that is assigned in a given loop and used outside of this loop, to have a $\phi$-node in the first block after a loop~\cite{LLVM_LCSSA}\cite{gcc_lcssa}.
This form is used to reduce special casing when transforming loops~\cite{aebi18bachelorarbeit}, and is therefore used through all of~\cref{sec:impl}.

To visualize this property,~\cref{fig:basics:LCSSA} depicts its effect.

\input{fig/lcssa-example.tex}

% FIRM
\section{\libFIRM}\label{sec:basics:firm}

\libFIRM~is a compiler middle- and back-end that takes a graph-based intermediate representation in SSA form, optimizes it and produces assembly code~\cite{libfirm}.
Since 1996 \libFIRM~is developed at Karlsruhe Institute of Technology (KIT).

A graph in \libFIRM~contains information about basics blocks, the control-flow, memory and, data dependencies.
Basics blocks in \libFIRM~contain further nodes that are responsible for the control-flow of the program.
These are pointed to by (other) basic blocks that are the target of these control-flow operations.
The resulting control-flow edges are represented by a red edge in visualizations of \libFIRM~graphs.
Any node that operates on memory are connected to memory nodes that are responsible for always assuring the current state of memory.
Memory is, like control flow, connected by edges, which are rather than being colored red, are colored blue in graphical representations.
Lastly, \libFIRM~has data dependency edges between nodes, which represent dependencies needed for calculations.

Another set of functionality that~\libFIRM~ provides is loop information.
\libFIRM~will not only (if applicable) be able to map blocks to their respective loops and vice-versa, but also has information on loop nesting structure.
This especially means that one can easily determine, whether a loop is an innermost loop~\cite{libfirm}.
Further,~\libFIRM~also allows for finding the basics block that is the header of a loop, given that it has a header~\cite{aebi18bachelorarbeit}.

In~\cref{fig:basics:firm} portrays an example firm graph of the program originally shown in~\cref{fig:basics:SSA-phi}.
It is especially to be noted that the graph is in SSA form, since it contains the $\phi$-node and has both memory, data and, control-flow edges.
\input{fig/max.tex}

% Unroll loops
\section{Loop unrolling}\label{sec:basics:unrolling}

Loop unrolling is a compiler optimization that attempts to duplicate the loop body, in order to reduce the loop controlling instructions, such as the loop condition or repetitive arithmetic~\cite{aho_ullman_1979}.

\Cref{fig:basics:old-loop-unrolling} shows a pseudo code example of unrolling a simple loop with a factor (the number of times the body is copied) of value four.
It is to be noted, that the loop condition has to be checked less often, on account of each loop iteration being four times as long as in the original program.

Further, it could also be used to vectorize the code, eliminate repeating conditions and for many other following optimizations~\cite{fog_2018}.
A negative side effect of loop unrolling is that the binary size increases and that there is more pressure on the code cache and registers, meaning more spilled values, when executing the application~\cite{Sarkar2001}.
Though the hope is that the benefit of less checking outweighs the drawbacks and trade-offs that come along with the technique.

\libFIRM~supports a restricted form of loop unrolling for loops that have static bounds and increments~\cite{aebi18bachelorarbeit}.
This optimization requires the intermediary representation to be in LCSSA form, which means the~\libFIRM~intermediary representation has to be converted into LCSSA form prior to the optimization running~\cite{aebi18bachelorarbeit}.
The benefits of this optimization were very slim, likely since the requirements for a loop to be unrollable are very strict.
With these restrictions in place, only approximately half of the innermost loops can be unrolled\footnote{Measured in spec2006}.


\input{fig/loop-unrolling.tex}

% Duff's Device
\section{Duff's device}\label{sec:basics:duffs}

A common problem with the loop unrolling shown in~\cref{fig:basics:old-loop-unrolling} is that it requires the number of iterations to be constant and divisible by the unroll factor.
A way to tackle this issue is to use a construct known as Duff's device: It preemptively unrolls a loop with a given factor and use~\textit{fixup} code to ensure that the remaining iterations are completed~\cite{duff_1983}.
Mathematically this means the construct executes the loop body $\floor{\frac{N}{f}} \cdot f + M \mod F = M$ times, where $M$ is the number of total times the loop body would be executed without the transformation and where $f$ is the unroll factor.
This property holds true as mod has the following property $x \mod y = x - \floor{\frac{x}{y}} * y$ and if we substitute $M$ for $x$ and $f$ for $y$ and rearrange for M, we get the aforementioned form.

\Cref{fig:basics:duff} shows an example of unrolling a loop with a non-divisible bound using a factor of eight\footnote{The original Duff's device used special C syntax to entangle the switch statement and loop~\cite{duff_1983}}.
Duff's device copied the loop body eight times and to ensure that the number of executions is correct, the first time around the code jumps to the corresponding instruction, depending on the need for fixup code.

Many compilers, such as GCC~\cite{gcc}, use Duff's device for unrolling loops and improving performance, while keeping code size relatively small.

\include{fig/loop-unrolling-duff}

\section{Overflow detection}\label{sec:basics:overflow}

When subtracting (or adding) two numbers that are in some form of integer-like representation the operation might over- or underflow, because the integer representation is a fixed bit two's complement represenation.
Due to the therefore inherent resulting limitations as for possible values, this problem is unavoidable, yet detectable.

\Cref{alg:basics:overflow:detect}~\cite{pmg_2009} shows a way to detect whether an overflow or underflow occurs for an operation $x - a, (x, a) \in (\NInt)^2$, by checking whether the result increased or decreased relative to the bounds and comparing it to what was expected: an increase or decrease.
\input{fig/alg-detect-overflow.tex}

