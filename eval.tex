\chapter{Evaluation}\label{sec:eval}

\section{Unrollability}\label{sec:eval:unrollability}

One of the primary goals of this thesis was to increase the number of loops that are unrollable within~\libFIRM.
To evaluate to which extent this goal was achieved\footnote{N.B.: The test was conducted with a max loop size of $\infty$}, we ran the benchmark suite \texttt{spec2006}, and logged how many loops we encountered, how many of them were innermost loops, how many could be unrolled using the old method, and how many that were previously not unrollable can now be unrolled.
Considering it is expected for many loops to have non-constant bounds, such as the length of a container data-structure (e.g., a list or an unbounded array), we predicted to cause a significant increase in unrollable loops.
\Cref{fig:eval:unrollability:cmp-unrollability} shows a table with the results.
We can see as mentioned in \cref{sec:basics:unrolling}, that prior to the new optimization, 4.17\% of the innermost loops could be unrolled.
Now we can unroll an additional 7.37\% of loops.
Contrasted to the baseline of the constant bound unrolled loops this is a 125.65\% increase.
This means we more than doubled the number of unrollable loops using our approach.
Furthermore, we note that more than 70\% of loops are innermost loops.
Thus, even if unrolling nested loops were advantageous -- which is highly doubted -- we would not miss out on many loops.


\input{fig/result-unrollability.tex}

\section{Performance}\label{sec:eval:perf}

Even though a high unrollability is a noble goal, any optimization aims to improve the runtime of the binaries it produces.
In order to evaluate the optimization in this regard, \texttt{spec2006} is used as a benchmark suite and run on a machine with an Intel Core~\textregistered~i7 6700 clocked at 3.4GHz.
We run the tests on the Ubuntu 16.04 operating system, with cparser~\cite{cparser} as the frontend for~\libFIRM, and the native \texttt{x86} backend of~\libFIRM~in use.
We use the same setup as used in the referenced work~\cite{aebi18bachelorarbeit}, such that we can get as comparable results as possible.

In order to evaluate the performance gain, we run the new optimization in conjunction with the old unrolling, given that it is intended as an extension.
As a result of there being two approaches for the fixup, as seen in \cref{sec:impl:fixup}, we will try both of these, to see if one or the other yields better binary runtimes.
Further, as described in~\cref{sec:impl:sel-factor}, the scope of the optimization is determined by the maximum unrolled size.
Therefore, all sizes~$l \in \{2^n, n \in \lbrack 5, 10 \rbrack \}$~are each tried for both the fixup code strategies.
The reason that we chose 32 as a lower bound, is that very small loops are already more than eight nodes in size and hence wouldn't be unrolled with a maximum size that is a power of two.
In order to compensate for measurement uncertainties, all benchmarks run ten times, and the average ($\mu$), as well as the standard deviation ($\sigma$) will be recorded and discussed.
We will compare all results to the reference benchmark run, which itself is a run of \texttt{spec2006} without any loop unrolling turned on.
These reference results can be seen in \cref{fig:eval:perf:ref}.

In order to evaluate our findings in terms of performance, we should compare them to unrollability broken down by benchmark.
\Cref{fig:eval:unrollability:cmp-unrollability-bench} shows the number of unrollable loops\footnote{Both constant and non-constant bound unrollable loops are considered together} compared to the total number of loops.
Like in \cref{fig:eval:unrollability:cmp-unrollability}, we assume a maximum size of infinity to collect this data.
Seeing this data, we would suspect \texttt{bzip2}, \texttt{mcf} and to a lesser extent \texttt{h264ref} to have the most considerable speedup.

\input{fig/result-unrollability-bench.tex}

\input{fig/bench-result-ref.tex}

\newpage

\subsection{Duff's device fixup}\label{sec:eval:perf:duff}

Figures~\ref{fig:eval:perf:duff:32} through~\ref{fig:eval:perf:duff:1024} show the obtained results.
While for most benchmarks the results hover around the 100\% mark, with no significant benefit or drawback, \texttt{h264ref} seems to profit from unrolling with maximum sizes 32 and 64, by being close to 4.5\% faster.
Though on account of the ratios of all the other benchmarks only diverting by three percent or less from the reference runtimes, unrolling does not seem to have a significant effect on performance.

Further, we can expect a small percentage of systemic errors in our measurements due to system process scheduling and similar factors.
Even though the standard deviations, owning they are usually very small, due to the highly controlled test environment, do not entirely account for these percentage deltas, they are small, yet measurable.
As the averages of benchmark runtimes are, independent of the maximum loop size, within $\lbrack 99\%, 101\% \rbrack$ we can consider them to be within the margin of error.

\subsection{Loop fixup}\label{sec:eval:perf:loop}

Figures~\ref{fig:eval:perf:loop:32} through~\ref{fig:eval:perf:loop:1024} show the results obtained for the unrolling run with the loop fixup code.
As was the case in~\cref{sec:eval:perf:duff}, there does not seem to be any noticeable performance gain or loss in any benchmark, except for \texttt{h264ref}, which again sped up through unrolling by upto 5\%.
The other benchmark were, compared to the reference, within the interval $\lbrack 99\%, 103\% \rbrack$.
It further becomes evident that there is no correlation between unrollability and performance gain, since, while \texttt{h264ref} has one of the highest unrollabilities, \texttt{bzip2} and \texttt{mcf} have higher unrollabilities, yet see no improvement.


\input{fig/bench-result-duff.tex}

\input{fig/bench-result-loop.tex}
